"""
=============================================
ä¼˜å…ˆçº§ç»éªŒå›æ”¾ï¼ˆPERï¼‰ç¤ºä¾‹
=============================================

PER æŒ‰ä¼˜å…ˆçº§é‡‡æ ·ç»éªŒï¼Œé‡ç‚¹å­¦ä¹ "æ„å¤–"çš„ç»éªŒã€‚
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
from prometheus.envs import make_gym_env
from prometheus.agents.dqn import DQNAgent, PERAgent
from prometheus.trainers import DQNTrainer, TrainerConfig
from prometheus.core import SumTree


def demonstrate_sumtree():
    """æ¼”ç¤º SumTree çš„ä½¿ç”¨"""
    print("=" * 60)
    print("ğŸŒ³ SumTree æ¼”ç¤º")
    print("=" * 60)

    tree = SumTree(capacity=8)

    # æ·»åŠ ä¸€äº›æ•°æ®
    for i in range(8):
        priority = i + 1  # ä¼˜å…ˆçº§ 1, 2, 3, ..., 8
        tree.add(priority, f"data_{i}")

    print(f"\nä¼˜å…ˆçº§æ€»å’Œ: {tree.total()}")  # åº”è¯¥æ˜¯ 36
    print(f"å­˜å‚¨æ•°é‡: {tree.n_entries}")

    # é‡‡æ ·å‡ æ¬¡
    print("\né‡‡æ ·ç»“æœï¼ˆæ¨¡æ‹Ÿï¼‰:")
    for _ in range(5):
        s = np.random.uniform(0, tree.total())
        idx, priority, data = tree.get(s)
        print(f"  é‡‡æ ·å€¼ {s:.1f} -> ä¼˜å…ˆçº§ {priority:.0f}, æ•°æ® {data}")

    # æ›´æ–°ä¼˜å…ˆçº§
    print("\næ›´æ–°ä¼˜å…ˆçº§ï¼ˆç¬¬ä¸€ä¸ªæ•°æ®ä» 1 æ”¹ä¸º 100ï¼‰:")
    idx = 7  # ç¬¬ä¸€ä¸ªå¶å­èŠ‚ç‚¹ç´¢å¼•
    tree.update(idx, 100)
    print(f"æ–°çš„æ€»å’Œ: {tree.total()}")


def train_per():
    """è®­ç»ƒ PER æ™ºèƒ½ä½“"""
    print("\n" + "=" * 60)
    print("ğŸ“Š è®­ç»ƒ PER æ™ºèƒ½ä½“")
    print("=" * 60)

    env = make_gym_env("CartPole-v1")
    agent = PERAgent(state_dim=4, action_dim=2, alpha=0.6, beta_start=0.4)
    config = TrainerConfig(max_episodes=300, eval_interval=50, log_interval=20)
    trainer = DQNTrainer(config)

    result = trainer.train(env, agent)
    print(f"\nPER æœ€ç»ˆå¾—åˆ†: {result['final_score']:.1f}")
    return agent, result


def compare_standard_vs_per():
    """å¯¹æ¯”æ ‡å‡† DQN å’Œ PER"""
    print("\n" + "=" * 60)
    print("ğŸ”¬ æ ‡å‡† DQN vs PER")
    print("=" * 60)

    config = TrainerConfig(
        max_episodes=200,
        eval_interval=100,
        log_interval=50,
        save_interval=1000
    )

    # è®­ç»ƒæ ‡å‡† DQN
    print("\n--- æ ‡å‡† DQN ---")
    env = make_gym_env("CartPole-v1")
    agent_standard = DQNAgent(state_dim=4, action_dim=2)
    trainer_standard = DQNTrainer(config)
    trainer_standard.train(env, agent_standard)
    eval_standard = trainer_standard.evaluate(env, agent_standard, n_episodes=20)
    print(f"\næ ‡å‡† DQN è¯„ä¼°å¾—åˆ†: {eval_standard['mean_score']:.1f} Â± {eval_standard['std_score']:.1f}")

    # è®­ç»ƒ PER
    print("\n--- PER ---")
    env = make_gym_env("CartPole-v1")
    agent_per = PERAgent(state_dim=4, action_dim=2)
    trainer_per = DQNTrainer(config)
    trainer_per.train(env, agent_per)
    eval_per = trainer_per.evaluate(env, agent_per, n_episodes=20)
    print(f"\nPER è¯„ä¼°å¾—åˆ†: {eval_per['mean_score']:.1f} Â± {eval_per['std_score']:.1f}")

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“ˆ å¯¹æ¯”ç»“æœ")
    print("=" * 60)
    print(f"æ ‡å‡† DQN:      {eval_standard['mean_score']:.1f}")
    print(f"PER:           {eval_per['mean_score']:.1f}")
    improvement = eval_per['mean_score'] - eval_standard['mean_score']
    print(f"æå‡:          {improvement:+.1f}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ä¼˜å…ˆçº§ç»éªŒå›æ”¾ç¤ºä¾‹")
    parser.add_argument("--mode", choices=["sumtree", "train", "compare"],
                        default="compare", help="è¿è¡Œæ¨¡å¼")
    args = parser.parse_args()

    if args.mode == "sumtree":
        demonstrate_sumtree()
    elif args.mode == "train":
        train_per()
    else:
        compare_standard_vs_per()
