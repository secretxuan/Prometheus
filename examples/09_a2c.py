"""
=============================================
A2Cï¼ˆActor-Criticï¼‰ç¤ºä¾‹
=============================================

A2C æ˜¯ Actor-Critic æ–¹æ³•çš„ä¸€ä¸ªé«˜æ•ˆå®ç°ã€‚

Actor-Critic çš„æ ¸å¿ƒæ€æƒ³ï¼š
1. Actorï¼ˆæ¼”å‘˜ï¼‰ï¼šç­–ç•¥ç½‘ç»œï¼Œé€‰æ‹©åŠ¨ä½œ
2. Criticï¼ˆè¯„è®ºå®¶ï¼‰ï¼šä»·å€¼ç½‘ç»œï¼Œè¯„ä¼°çŠ¶æ€ä»·å€¼

ç›¸æ¯” REINFORCE çš„ä¼˜åŠ¿ï¼š
1. æ–¹å·®æ›´ä½ï¼ˆCritic æä¾›äº†åŸºçº¿ï¼‰
2. æ”¶æ•›æ›´å¿«
3. å¯ä»¥åœ¨çº¿æ›´æ–°ï¼ˆä¸éœ€è¦ç­‰ episode ç»“æŸï¼‰

A2C çš„ç‰¹ç‚¹ï¼š
- ä½¿ç”¨ Advantage å‡½æ•°ï¼šA(s,a) = Q(s,a) - V(s)
- åŒæ­¥æ›´æ–°ï¼ˆç›¸æ¯” A3C çš„å¼‚æ­¥æ›´æ–°ï¼‰
"""

import torch
from prometheus.envs.gym_wrapper import make_gym_env
from prometheus.agents.policy_gradient.a2c import A2CAgent
from prometheus.trainers.policy_gradient.a2c import A2CTrainer, TrainerConfig
from prometheus.core import Config


def main():
    # === åˆ›å»ºç¯å¢ƒ ===
    env = make_gym_env("CartPole-v1")

    # === é…ç½® ===
    agent_config = Config(
        LEARNING_RATE=1e-3,
        GAMMA=0.99,
    )

    trainer_config = TrainerConfig(
        max_episodes=500,
        max_steps_per_episode=500,
        eval_interval=50,
        eval_episodes=10,
        save_interval=200,
        save_dir="checkpoints/a2c",
        log_interval=10,
    )

    # === åˆ›å»ºæ™ºèƒ½ä½“ ===
    state_dim = env.spec.observation_space.shape[0]
    action_dim = env.spec.action_space._gym_space.n

    agent = A2CAgent(
        state_dim=state_dim,
        action_dim=action_dim,
        config=agent_config,
        device="cuda" if torch.cuda.is_available() else "cpu"
    )

    # === åˆ›å»ºè®­ç»ƒå™¨ ===
    trainer = A2CTrainer(config=trainer_config)

    # === å¼€å§‹è®­ç»ƒ ===
    results = trainer.train(env, agent, n_step_update=False)

    # === æœ€ç»ˆè¯„ä¼° ===
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€ç»ˆè¯„ä¼°")
    print("=" * 60)
    final_metrics = trainer.evaluate(env, agent, n_episodes=20)
    for k, v in final_metrics.items():
        print(f"  {k}: {v:.2f}")

    env.close()


if __name__ == "__main__":
    main()
