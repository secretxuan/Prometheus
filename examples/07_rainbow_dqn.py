"""
=============================================
Rainbow DQN ç¤ºä¾‹
=============================================

Rainbow æ•´åˆäº† DQN çš„å¤šç§æ”¹è¿›ï¼š
- Dueling DQN ç½‘ç»œç»“æ„
- Double DQN çš„ç›®æ ‡ Q è®¡ç®—
- ä¼˜å…ˆçº§ç»éªŒå›æ”¾ï¼ˆPERï¼‰

è®ºæ–‡: Rainbow: Combining Improvements in Deep Reinforcement Learning (2017)
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
from prometheus.envs import make_gym_env
from prometheus.agents.dqn import (
    DQNAgent,
    DoubleDQNAgent,
    DuelingDQNAgent,
    PERAgent,
    RainbowAgent
)
from prometheus.trainers import DQNTrainer, TrainerConfig


def train_rainbow():
    """è®­ç»ƒ Rainbow æ™ºèƒ½ä½“"""
    print("=" * 60)
    print("ğŸŒˆ è®­ç»ƒ Rainbow DQN")
    print("=" * 60)
    print("\nRainbow æ•´åˆçš„æ”¹è¿›:")
    print("  âœ“ Dueling DQN: Q(s,a) = V(s) + A(s,a)")
    print("  âœ“ Double DQN: ä¸»ç½‘ç»œé€‰åŠ¨ä½œï¼Œç›®æ ‡ç½‘ç»œè¯„ä¼°")
    print("  âœ“ PER: æŒ‰ä¼˜å…ˆçº§é‡‡æ ·ç»éªŒ")

    env = make_gym_env("CartPole-v1")
    agent = RainbowAgent(state_dim=4, action_dim=2)
    config = TrainerConfig(max_episodes=300, eval_interval=50, log_interval=20)
    trainer = DQNTrainer(config)

    result = trainer.train(env, agent)
    print(f"\nRainbow æœ€ç»ˆå¾—åˆ†: {result['final_score']:.1f}")
    return agent, result


def compare_all():
    """å¯¹æ¯”æ‰€æœ‰ DQN å˜ä½“"""
    print("\n" + "=" * 60)
    print("ğŸ”¬ DQN ç³»åˆ—ç®—æ³•å¯¹æ¯”")
    print("=" * 60)

    config = TrainerConfig(
        max_episodes=200,
        eval_interval=100,
        log_interval=50,
        save_interval=1000
    )

    results = {}

    algorithms = [
        ("æ ‡å‡† DQN", lambda: DQNAgent(state_dim=4, action_dim=2)),
        ("Double DQN", lambda: DoubleDQNAgent(state_dim=4, action_dim=2)),
        ("Dueling DQN", lambda: DuelingDQNAgent(state_dim=4, action_dim=2)),
        ("PER", lambda: PERAgent(state_dim=4, action_dim=2)),
        ("Rainbow", lambda: RainbowAgent(state_dim=4, action_dim=2)),
    ]

    for name, agent_fn in algorithms:
        print(f"\n--- {name} ---")
        env = make_gym_env("CartPole-v1")
        agent = agent_fn()
        trainer = DQNTrainer(config)
        trainer.train(env, agent)
        eval_result = trainer.evaluate(env, agent, n_episodes=20)
        results[name] = eval_result['mean_score']
        print(f"\n{name} è¯„ä¼°å¾—åˆ†: {eval_result['mean_score']:.1f} Â± {eval_result['std_score']:.1f}")

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“ˆ å¯¹æ¯”ç»“æœï¼ˆæŒ‰å¾—åˆ†æ’åºï¼‰")
    print("=" * 60)

    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)
    for i, (name, score) in enumerate(sorted_results, 1):
        bar = "â–ˆ" * int(score / 20)
        print(f"{i}. {name:15s} {score:5.1f} {bar}")

    print(f"\nğŸ† æœ€ä½³ç®—æ³•: {sorted_results[0][0]}")


def analyze_rainbow_components():
    """åˆ†æ Rainbow çš„å„ä¸ªç»„ä»¶"""
    print("=" * 60)
    print("ğŸ” Rainbow ç»„ä»¶åˆ†æ")
    print("=" * 60)

    agent = RainbowAgent(state_dim=4, action_dim=2)

    print("\n1. Dueling ç½‘ç»œç»“æ„:")
    print("   Q(s,a) = V(s) + A(s,a) - mean(A)")

    state = np.array([0, 0, 0, 0], dtype=np.float32)
    value, advantage = agent.policy.get_value_and_advantage(state)
    q_values = agent.policy.get_q_values(state)

    print(f"   çŠ¶æ€ä»·å€¼ V(s): {value:.4f}")
    print(f"   åŠ¨ä½œä¼˜åŠ¿ A(s,a): {advantage}")
    print(f"   Q å€¼: {q_values}")

    print("\n2. Double DQN ç›®æ ‡è®¡ç®—:")
    print("   next_action = policy_network(next_state).argmax()")
    print("   target_q = target_network(next_state)[next_action]")

    print("\n3. ä¼˜å…ˆçº§ç»éªŒå›æ”¾ (PER):")
    print(f"   Alpha (ä¼˜å…ˆçº§æŒ‡æ•°): {agent.replay_buffer.alpha}")
    print(f"   Beta Start (é‡è¦æ€§é‡‡æ ·): {agent.replay_buffer.beta_start}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Rainbow DQN ç¤ºä¾‹")
    parser.add_argument("--mode", choices=["analyze", "train", "compare"],
                        default="compare", help="è¿è¡Œæ¨¡å¼")
    args = parser.parse_args()

    if args.mode == "analyze":
        analyze_rainbow_components()
    elif args.mode == "train":
        train_rainbow()
    else:
        compare_all()
