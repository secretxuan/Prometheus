"""
=============================================
REINFORCE è®­ç»ƒå™¨
=============================================
"""

import time
from pathlib import Path
from typing import Dict, Any
import numpy as np

from prometheus.trainers.base import BaseTrainer, TrainerConfig, Callback
from prometheus.agents.policy_gradient.reinforce import REINFORCEAgent
from prometheus.envs.base import EnvWrapper


class ProgressCallback(Callback):
    """
    è¿›åº¦æ‰“å°å›è°ƒ
    """

    def __init__(self, interval: int = 10):
        self.interval = interval
        self.scores = []
        self.episode_times = []

    def on_episode_end(self, trainer, episode: int, metrics: Dict):
        self.scores.append(metrics.get("score", 0))
        self.episode_times.append(metrics.get("duration", 0))

        if episode % self.interval == 0:
            avg_score = np.mean(self.scores[-self.interval:])
            loss = metrics.get("loss", 0)

            print(f"Episode {episode:4d} | "
                  f"å¾—åˆ†: {metrics.get('score', 0):3.0f} | "
                  f"å¹³å‡: {avg_score:5.1f} | "
                  f"æŸå¤±: {loss:.3f}")


class REINFORCETrainer(BaseTrainer):
    """
    REINFORCE è®­ç»ƒå™¨

    ä¸ DQN è®­ç»ƒå™¨çš„åŒºåˆ«ï¼š
    1. æ¯ä¸ª episode ç»“æŸåæ‰æ›´æ–°
    2. ä¸éœ€è¦ç›®æ ‡ç½‘ç»œ
    3. ä¸éœ€è¦ç»éªŒæ± 
    """

    def __init__(self, config: TrainerConfig = None):
        super().__init__(config)
        self._setup_callbacks()

    def _setup_callbacks(self):
        """è®¾ç½®é»˜è®¤å›è°ƒ"""
        if not self.config.callbacks:
            self.config.callbacks = [ProgressCallback(interval=self.config.log_interval)]

    def train(
        self,
        env: EnvWrapper,
        agent: REINFORCEAgent
    ) -> Dict[str, Any]:
        """
        è®­ç»ƒæ™ºèƒ½ä½“

        Args:
            env: ç¯å¢ƒ
            agent: REINFORCE æ™ºèƒ½ä½“

        Returns:
            è®­ç»ƒç»“æœ
        """
        # è·å–ç¯å¢ƒä¿¡æ¯
        state_dim = env.spec.observation_space.shape[0]
        action_dim = env.spec.action_space._gym_space.n

        print("=" * 60)
        print("ğŸ›ï¸  Prometheus - REINFORCE è®­ç»ƒ")
        print("=" * 60)
        print(f"ç¯å¢ƒ: {env.spec.name}")
        print(f"çŠ¶æ€ç»´åº¦: {state_dim}")
        print(f"åŠ¨ä½œæ•°é‡: {action_dim}")
        print(f"æœ€å¤§ Episode: {self.config.max_episodes}")
        print("=" * 60)
        print()

        # è®­ç»ƒå¾ªç¯
        for callback in self.config.callbacks:
            callback.on_train_start(self)

        for episode in range(1, self.config.max_episodes + 1):
            episode_start = time.time()

            for callback in self.config.callbacks:
                callback.on_episode_start(self, episode)

            # è¿è¡Œä¸€ä¸ª episode
            metrics = self._run_episode(env, agent)
            metrics["duration"] = time.time() - episode_start

            # === REINFORCE ç‰¹ç‚¹ï¼šepisode ç»“æŸåå­¦ä¹  ===
            learn_metrics = agent.learn()
            metrics.update(learn_metrics)

            for callback in self.config.callbacks:
                callback.on_episode_end(self, episode, metrics)

            # å®šæœŸè¯„ä¼°
            if episode % self.config.eval_interval == 0:
                eval_metrics = self.evaluate(env, agent, render=False)
                print(f"  â†’ è¯„ä¼°å¹³å‡å¾—åˆ†: {eval_metrics['mean_score']:.1f}")

            # å®šæœŸä¿å­˜
            if episode % self.config.save_interval == 0:
                save_path = Path(self.config.save_dir) / f"reinforce_ep{episode}.pth"
                save_path.parent.mkdir(parents=True, exist_ok=True)
                agent.save(str(save_path))

        for callback in self.config.callbacks:
            callback.on_train_end(self)

        print()
        print("=" * 60)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print("=" * 60)

        return {"episodes": episode, "final_score": metrics.get("score", 0)}

    def _run_episode(self, env: EnvWrapper, agent: REINFORCEAgent) -> Dict:
        """è¿è¡Œä¸€ä¸ª episode"""
        agent.reset()
        state, _ = env.reset()
        score = 0
        done = False
        step = 0

        while not done and step < self.config.max_steps_per_episode:
            # é€‰æ‹©åŠ¨ä½œ
            action = agent.act(state, training=True)

            # æ‰§è¡ŒåŠ¨ä½œ
            next_state, reward, terminated, truncated, _ = env.step(action)
            done = terminated or truncated

            # å­˜å‚¨ç»éªŒ
            agent.remember(state, action, reward, next_state, done)

            state = next_state
            score += reward
            step += 1

        return {"score": score, "steps": step}

    def evaluate(
        self,
        env: EnvWrapper,
        agent: REINFORCEAgent,
        n_episodes: int = None,
        render: bool = False
    ) -> Dict[str, float]:
        """
        è¯„ä¼°æ™ºèƒ½ä½“

        Args:
            env: ç¯å¢ƒ
            agent: æ™ºèƒ½ä½“
            n_episodes: è¯„ä¼°è½®æ•°
            render: æ˜¯å¦æ¸²æŸ“

        Returns:
            è¯„ä¼°ç»“æœ
        """
        if n_episodes is None:
            n_episodes = self.config.eval_episodes

        scores = []
        agent.set_mode(training=False)

        for _ in range(n_episodes):
            agent.reset()
            state, _ = env.reset()
            score = 0
            done = False

            while not done:
                action = agent.act(state, training=False)
                state, reward, terminated, truncated, _ = env.step(action)
                done = terminated or truncated
                score += reward

            scores.append(score)

        agent.set_mode(training=True)

        return {
            "mean_score": np.mean(scores),
            "std_score": np.std(scores),
            "min_score": np.min(scores),
            "max_score": np.max(scores)
        }

    def save_checkpoint(self, path: str, agent: REINFORCEAgent):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        agent.save(path)

    def load_checkpoint(self, path: str, agent: REINFORCEAgent):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        agent.load(path)
