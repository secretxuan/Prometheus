# ğŸ›ï¸ Prometheus - å¼ºåŒ–å­¦ä¹ æ¡†æ¶

> ä¸ºäººç±»å¸¦æ¥ç«ç§çš„ RL æ¡†æ¶

## ğŸ“– è¿™ä¸ªé¡¹ç›®æ˜¯ä»€ä¹ˆï¼Ÿ

Prometheus æ˜¯ä¸€ä¸ª**ä»é›¶å¼€å§‹**æ‰“é€ çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç›®çš„æ˜¯é€šè¿‡å®é™…åŠ¨æ‰‹æ¥å­¦ä¹  AI Infrastructureã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- ç†è§£å¼ºåŒ–å­¦ä¹ çš„æ ¸å¿ƒåŸç†
- å­¦ä¹ å¦‚ä½•è®¾è®¡é«˜æ•ˆçš„ AI æ¡†æ¶
- æŒæ¡ PyTorch å’Œç³»ç»Ÿç¼–ç¨‹çš„ç»“åˆ
- æœ€ç»ˆå®ç°ä¸€ä¸ªå¯ç”¨çš„ RL æ¡†æ¶

## ğŸ“ é¡¹ç›®ç»“æ„

```
Prometheus/
â”œâ”€â”€ prometheus/          # æ¡†æ¶æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py              # Config, ReplayBuffer, SumTree, PrioritizedReplayBuffer
â”‚   â”œâ”€â”€ envs/                # ç¯å¢ƒæ¨¡å—
â”‚   â”‚   â”œâ”€â”€ base.py          # ç¯å¢ƒæŠ½è±¡æ¥å£
â”‚   â”‚   â””â”€â”€ gym_wrapper.py   # Gym ç¯å¢ƒåŒ…è£…å™¨
â”‚   â”œâ”€â”€ policies/            # ç­–ç•¥æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ base.py          # ç­–ç•¥æŠ½è±¡æ¥å£
â”‚   â”‚   â””â”€â”€ dqn/             # DQN ç³»åˆ—ç­–ç•¥ âœ¨ v0.2.0
â”‚   â”‚       â”œâ”€â”€ base.py      # DQN åŸºç±»
â”‚   â”‚       â”œâ”€â”€ double.py    # Double DQN
â”‚   â”‚       â”œâ”€â”€ dueling.py   # Dueling DQN
â”‚   â”‚       â””â”€â”€ rainbow.py   # Rainbow
â”‚   â”œâ”€â”€ agents/              # æ™ºèƒ½ä½“æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ base.py          # æ™ºèƒ½ä½“æŠ½è±¡æ¥å£
â”‚   â”‚   â””â”€â”€ dqn/             # DQN ç³»åˆ—æ™ºèƒ½ä½“ âœ¨ v0.2.0
â”‚   â”‚       â”œâ”€â”€ base.py      # DQN åŸºç±»
â”‚   â”‚       â”œâ”€â”€ double.py    # Double DQN
â”‚   â”‚       â”œâ”€â”€ dueling.py   # Dueling DQN
â”‚   â”‚       â”œâ”€â”€ per.py       # PER
â”‚   â”‚       â””â”€â”€ rainbow.py   # Rainbow
â”‚   â””â”€â”€ trainers/            # è®­ç»ƒå™¨æ¨¡å—
â”‚       â”œâ”€â”€ base.py          # è®­ç»ƒå™¨æŠ½è±¡æ¥å£
â”‚       â””â”€â”€ dqn/             # DQN è®­ç»ƒå™¨
â”‚           â””â”€â”€ base.py      # é€šç”¨ DQN è®­ç»ƒå™¨
â”œâ”€â”€ examples/            # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ 01_cartpole_dqn.py   # DQN è®­ç»ƒç¤ºä¾‹ï¼ˆv0.0.1ï¼‰
â”‚   â”œâ”€â”€ 02_watch_agent.py    # è§‚çœ‹æ™ºèƒ½ä½“è¡¨ç°
â”‚   â”œâ”€â”€ 03_new_framework.py  # ä½¿ç”¨æ–°æ¡†æ¶ï¼ˆv0.1.0ï¼‰
â”‚   â”œâ”€â”€ 04_double_dqn.py     # Double DQN âœ¨ v0.2.0
â”‚   â”œâ”€â”€ 05_dueling_dqn.py    # Dueling DQN âœ¨ v0.2.0
â”‚   â”œâ”€â”€ 06_per_dqn.py        # ä¼˜å…ˆçº§ç»éªŒå›æ”¾ âœ¨ v0.2.0
â”‚   â””â”€â”€ 07_rainbow_dqn.py    # Rainbow (æ•´åˆæ‰€æœ‰æ”¹è¿›) âœ¨ v0.2.0
â”œâ”€â”€ docs/                # å­¦ä¹ ç¬”è®°
â”‚   â”œâ”€â”€ plan.md             # å­¦ä¹ è§„åˆ’
â”‚   â”œâ”€â”€ å­¦ä¹ ç¬”è®°_01_ç«ç§ç¯‡.md
â”‚   â””â”€â”€ å­¦ä¹ ç¬”è®°_02_é“¸ç‚‰ç¯‡.md
â”œâ”€â”€ tests/               # æµ‹è¯•ä»£ç 
â”œâ”€â”€ venv/                # è™šæ‹Ÿç¯å¢ƒ
â”œâ”€â”€ run.sh               # ä¾¿æ·è¿è¡Œè„šæœ¬
â””â”€â”€ requirements.txt     # ä¾èµ–åˆ—è¡¨
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# è™šæ‹Ÿç¯å¢ƒå·²åˆ›å»ºï¼Œç›´æ¥æ¿€æ´»å³å¯
source venv/bin/activate

# æˆ–è€…åœ¨ Windows ä¸Š
venv\Scripts\activate
```

### 2. è¿è¡Œç¤ºä¾‹

**æ–¹å¼ä¸€ï¼šä½¿ç”¨ run.sh è„šæœ¬ï¼ˆæ¨èï¼‰**
```bash
./run.sh examples/03_new_framework.py
```

**æ–¹å¼äºŒï¼šç›´æ¥è¿è¡Œï¼ˆéœ€è¦è®¾ç½® PYTHONPATHï¼‰**
```bash
source venv/bin/activate
PYTHONPATH=. python examples/03_new_framework.py
```

## ğŸ“š ç¤ºä¾‹è¯´æ˜

### 03_new_framework.py - æ–°æ¡†æ¶ä½¿ç”¨ âœ¨ æ¨è

å±•ç¤º Prometheus v0.1.0 æ–°æ¡†æ¶çš„ä½¿ç”¨æ–¹å¼ã€‚

**è¿è¡Œ**ï¼š
```bash
./run.sh examples/03_new_framework.py
```

**ä»£ç ç¤ºä¾‹**ï¼š
```python
from prometheus.envs import make_gym_env
from prometheus.agents import DQNAgent
from prometheus.trainers import DQNTrainer, TrainerConfig

# åˆ›å»ºç¯å¢ƒ
env = make_gym_env("CartPole-v1")

# åˆ›å»ºæ™ºèƒ½ä½“
agent = DQNAgent(state_dim=4, action_dim=2)

# åˆ›å»ºè®­ç»ƒå™¨
config = TrainerConfig(max_episodes=500)
trainer = DQNTrainer(config=config)

# å¼€å§‹è®­ç»ƒ
trainer.train(env, agent)
```

### 04_double_dqn.py - Double DQN âœ¨ v0.2.0

å±•ç¤º Double DQN çš„ä½¿ç”¨ï¼Œè§£å†³ Q å€¼è¿‡é«˜ä¼°è®¡é—®é¢˜ã€‚

**è¿è¡Œ**ï¼š
```bash
./run.sh examples/04_double_dqn.py
```

**æ ¸å¿ƒæ”¹è¿›**ï¼šç”¨ä¸»ç½‘ç»œé€‰åŠ¨ä½œï¼Œç›®æ ‡ç½‘ç»œè¯„ä¼°ä»·å€¼

### 05_dueling_dqn.py - Dueling DQN âœ¨ v0.2.0

å±•ç¤º Dueling DQN çš„ä½¿ç”¨ï¼Œå°† Q å€¼åˆ†è§£ä¸ºçŠ¶æ€ä»·å€¼å’ŒåŠ¨ä½œä¼˜åŠ¿ã€‚

**è¿è¡Œ**ï¼š
```bash
./run.sh examples/05_dueling_dqn.py
```

**æ ¸å¿ƒæ”¹è¿›**ï¼šQ(s,a) = V(s) + A(s,a) - mean(A)

### 06_per_dqn.py - ä¼˜å…ˆçº§ç»éªŒå›æ”¾ âœ¨ v0.2.0

å±•ç¤º PER çš„ä½¿ç”¨ï¼ŒæŒ‰ä¼˜å…ˆçº§é‡‡æ ·ç»éªŒã€‚

**è¿è¡Œ**ï¼š
```bash
./run.sh examples/06_per_dqn.py
```

**æ ¸å¿ƒæ”¹è¿›**ï¼šæŒ‰ TD è¯¯å·®ä¼˜å…ˆçº§é‡‡æ ·ï¼Œæé«˜å­¦ä¹ æ•ˆç‡

### 07_rainbow_dqn.py - Rainbow âœ¨ v0.2.0

å±•ç¤º Rainbow çš„ä½¿ç”¨ï¼Œæ•´åˆæ‰€æœ‰ DQN æ”¹è¿›ã€‚

**è¿è¡Œ**ï¼š
```bash
./run.sh examples/07_rainbow_dqn.py
```

**æ ¸å¿ƒæ”¹è¿›**ï¼šDueling + Double + PER

### 01_cartpole_dqn.py - DQN è®­ç»ƒ

å¼ºåŒ–å­¦ä¹ çš„ "Hello World"ï¼Œç”¨ DQN ç®—æ³•è§£å†³ CartPole é—®é¢˜ã€‚

**è¿è¡Œ**ï¼š
```bash
./run.sh examples/01_cartpole_dqn.py
```

### 02_watch_agent.py - è§‚çœ‹æ™ºèƒ½ä½“

å¿«é€Ÿè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åæ‰“å¼€çª—å£è§‚çœ‹æ™ºèƒ½ä½“å¦‚ä½•å¹³è¡¡æ†å­ã€‚

**è¿è¡Œ**ï¼š
```bash
./run.sh examples/02_watch_agent.py
```

**æ³¨æ„**ï¼šéœ€è¦å›¾å½¢ç•Œé¢æ”¯æŒã€‚

## ğŸ“– å­¦ä¹ è¿›åº¦

- [x] é˜¶æ®µä¸€ï¼šç«ç§ - è·‘é€šç¬¬ä¸€ä¸ª RL å®éªŒï¼ˆv0.0.1ï¼‰
- [x] é˜¶æ®µäºŒï¼šé“¸ç‚‰ - è®¾è®¡æ¡†æ¶åŸºç¡€æ¶æ„ï¼ˆv0.1.0ï¼‰
- [x] é˜¶æ®µä¸‰ï¼ˆDQN æ”¹è¿›ç‰ˆï¼‰ï¼šæ·»æŸ´ - Double DQN, Dueling DQN, PER, Rainbowï¼ˆv0.2.0ï¼‰âœ¨ å½“å‰ç‰ˆæœ¬
- [ ] é˜¶æ®µä¸‰ï¼ˆç­–ç•¥æ¢¯åº¦ï¼‰ï¼šæ·»æŸ´ - REINFORCE, A2C, PPO
- [ ] é˜¶æ®µå››ï¼šç‚¼é‡‘ - æ€§èƒ½ä¼˜åŒ–
- [ ] é˜¶æ®µäº”ï¼šç‡åŸ - ç”Ÿæ€å®Œå–„

## ğŸ”§ æ¡†æ¶ API

### ç¯å¢ƒæ¨¡å— (prometheus.envs)

```python
from prometheus.envs import make_gym_env

# åˆ›å»º Gym ç¯å¢ƒ
env = make_gym_env("CartPole-v1")
obs, info = env.reset()
obs, reward, done, truncated, info = env.step(action)
```

### æ™ºèƒ½ä½“æ¨¡å— (prometheus.agents)

```python
from prometheus.agents import DQNAgent

agent = DQNAgent(state_dim=4, action_dim=2)
action = agent.act(state)           # é€‰æ‹©åŠ¨ä½œ
agent.remember(s, a, r, s2, done)   # å­˜å‚¨ç»éªŒ
metrics = agent.learn()             # å­¦ä¹ 
```

### è®­ç»ƒå™¨æ¨¡å— (prometheus.trainers)

```python
from prometheus.trainers import DQNTrainer, TrainerConfig

config = TrainerConfig(
    max_episodes=1000,
    eval_interval=100,
    log_interval=10
)
trainer = DQNTrainer(config=config)
trainer.train(env, agent)
```

## ğŸ“– å­¦ä¹ èµ„æº

- [Spinning Up in RL (OpenAI)](https://spinningup.openai.com/)
- [DQN è®ºæ–‡](https://www.nature.com/articles/nature14236)
- [Gymnasium æ–‡æ¡£](https://gymnasium.farama.org/)
- [PyTorch æ•™ç¨‹](https://pytorch.org/tutorials/)

## ğŸ“ ç‰ˆæœ¬å†å²

### v0.2.0 (æ·»æŸ´ç‰ˆæœ¬ - DQN æ”¹è¿›ç‰ˆ) - å½“å‰ç‰ˆæœ¬ âœ¨
- âœ¨ Double DQNï¼šè§£è€¦åŠ¨ä½œé€‰æ‹©å’Œä»·å€¼è¯„ä¼°
- âœ¨ Dueling DQNï¼šQ(s,a) = V(s) + A(s,a) ç»“æ„
- âœ¨ ä¼˜å…ˆçº§ç»éªŒå›æ”¾ï¼ˆPERï¼‰ï¼šSumTree + ä¼˜å…ˆçº§é‡‡æ ·
- âœ¨ Rainbowï¼šæ•´åˆæ‰€æœ‰ DQN æ”¹è¿›
- âœ¨ SumTree æ•°æ®ç»“æ„
- âœ¨ DQN æ¨¡å—åŒ–é‡æ„ï¼ˆdqn/ å­ç›®å½•ï¼‰

### v0.1.0 (é“¸ç‚‰ç‰ˆæœ¬)
- âœ¨ æ¨¡å—åŒ–æ¶æ„è®¾è®¡
- âœ¨ ç¯å¢ƒæ¨¡å— (envs)
- âœ¨ ç­–ç•¥æ¨¡å— (policies)
- âœ¨ æ™ºèƒ½ä½“æ¨¡å— (agents)
- âœ¨ è®­ç»ƒå™¨æ¨¡å— (trainers)
- âœ¨ å›è°ƒç³»ç»Ÿ

### v0.0.1 (ç«ç§ç‰ˆæœ¬)
- DQN ç®—æ³•å®ç°
- CartPole ç¤ºä¾‹
- åŸºç¡€è®­ç»ƒå¾ªç¯

## ğŸ§ª ç®—æ³•å¯¹æ¯”

| ç®—æ³• | æ ¸å¿ƒæ”¹è¿› | é€‚ç”¨åœºæ™¯ |
|------|----------|----------|
| DQN | åŸºå‡†ç®—æ³• | ç¦»æ•£åŠ¨ä½œç©ºé—´ï¼Œç®€å•ç¯å¢ƒ |
| Double DQN | è§£è€¦é€‰æ‹©å’Œè¯„ä¼° | å®¹æ˜“è¿‡é«˜ä¼°è®¡ Q å€¼çš„åœºæ™¯ |
| Dueling DQN | V(s) + A(s,a) åˆ†è§£ | åŠ¨ä½œä»·å€¼ç›¸è¿‘çš„çŠ¶æ€ |
| PER | ä¼˜å…ˆçº§é‡‡æ · | ç»éªŒè´¨é‡å·®å¼‚å¤§çš„åœºæ™¯ |
| Rainbow | æ•´åˆæ‰€æœ‰æ”¹è¿› | è¿½æ±‚æœ€ä½³æ€§èƒ½ |
